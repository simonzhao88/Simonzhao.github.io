{"title":"爬虫初探","slug":"爬虫初探","date":"2018-06-15T08:24:42.000Z","updated":"2018-06-25T09:13:45.618Z","comments":true,"path":"api/articles/爬虫初探.json","photos":[],"link":"","excerpt":"爬虫初探简介网络爬虫（Web Spider。又被称为网页蜘蛛。网络机器人，又称为网页追逐者），是一种依照一定的规则，自己主动的抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁，自己主动索引。模拟程序或者蠕虫。假设把互联网比喻成一个蜘蛛网，那么Spider就是在网上爬来爬去的蜘蛛。网络蜘蛛是通过网页的链接地址来寻找网页的。从站点某一个页面（一般是首页）開始，读取网页的内容。找到在网页中的其他链接地址。然后通过这些链接地址寻找下一个网页。这样一直循环下去，直到把这个站点全部的网页都抓取完为止。假设把整个互联网当成一个站点。那么网络蜘蛛就能够用这个原理把互联网上全部的网页都抓取下来。这样看来，网络爬虫就是一个爬行程序，一个抓取网页的程序。简单地说，网络爬虫的基本任务就是抓取网页内容。1.爬虫程序设计1.1 获取网页信息： ulrllib、urllib3、requests<br>1<br>2<br>3<br>requests为第三方的库，需要安装才能使用<br><br>pip install requests<br>","covers":null,"content":"<h1 id=\"爬虫初探\"><a href=\"#爬虫初探\" class=\"headerlink\" title=\"爬虫初探\"></a>爬虫初探</h1><h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>网络爬虫（Web Spider。又被称为网页蜘蛛。网络机器人，又称为网页追逐者），是一种依照一定的规则，自己主动的抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁，自己主动索引。模拟程序或者蠕虫。假设把互联网比喻成一个蜘蛛网，那么Spider就是在网上爬来爬去的蜘蛛。</p>\n<p>网络蜘蛛是通过网页的链接地址来寻找网页的。从站点某一个页面（一般是首页）開始，读取网页的内容。找到在网页中的其他链接地址。然后通过这些链接地址寻找下一个网页。这样一直循环下去，直到把这个站点全部的网页都抓取完为止。假设把整个互联网当成一个站点。那么网络蜘蛛就能够用这个原理把互联网上全部的网页都抓取下来。这样看来，网络爬虫就是一个爬行程序，一个抓取网页的程序。</p>\n<p><em>简单地说，网络爬虫的基本任务就是抓取网页内容。</em></p>\n<h3 id=\"1-爬虫程序设计\"><a href=\"#1-爬虫程序设计\" class=\"headerlink\" title=\"1.爬虫程序设计\"></a>1.爬虫程序设计</h3><p><strong>1.1 获取网页信息： ulrllib、urllib3、requests</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">requests为第三方的库，需要安装才能使用</span><br><span class=\"line\"></span><br><span class=\"line\">pip install requests</span><br></pre></td></tr></table></figure></p>\n<a id=\"more\"></a>\n<p><strong>1.2解析网页信息：beautifulsoup4(bs4)、re、xpath、lxml</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bs4为第三方的库，需要安装才能使用</span><br><span class=\"line\"></span><br><span class=\"line\">pip install beautifulsoup4</span><br><span class=\"line\"></span><br><span class=\"line\">使用的时候 <span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup 这样导入</span><br></pre></td></tr></table></figure>\n<p>Python 标准库中自带了 xml 模块，但是性能不够好，而且缺乏一些人性化的 API，相比之下，第三方库 lxml 是用 Cython 实现的，而且增加了很多实用的功能。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">安装lxml，在新版本中无法使用<span class=\"keyword\">from</span> lxml <span class=\"keyword\">import</span> etree</span><br><span class=\"line\"> </span><br><span class=\"line\"> pip install lxml 并不推荐这样去安装lxml</span><br><span class=\"line\"></span><br><span class=\"line\"> 推荐安装的方法：访问网站(https://www.lfd.uci.edu/~gohlke/pythonlibs/<span class=\"comment\">#lxml)下载lxml的安装whl文件，然后进行安装。</span></span><br><span class=\"line\"> </span><br><span class=\"line\"> pip install lxml<span class=\"number\">-4.2</span><span class=\"number\">.1</span>-cp36-cp36m-win_amd64.whl</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2-网页分析\"><a href=\"#2-网页分析\" class=\"headerlink\" title=\"2.网页分析\"></a>2.网页分析</h3><p><strong>2.1 请求头分析</strong></p>\n<p>使用chrome或者firefox浏览器，打开需要爬取的网页，F12进入开发者模式，查看网页请求头。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 浏览器告诉服务器可以接收的文本类型, */*表示任何类型都可以接收</span></span><br><span class=\"line\">Accept: text/html, */*;q=<span class=\"number\">0.8</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 浏览器告诉服务器，数据可以压缩，页面可以解压数据然后进行渲染。做爬虫的时候，最好不要写该参数</span></span><br><span class=\"line\">Accept-Encoding: gzip, deflate </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 语言类型</span></span><br><span class=\"line\">Accept-Language: zh-CN,zh;q=<span class=\"number\">0.9</span> </span><br><span class=\"line\"></span><br><span class=\"line\">Cache-Control: max-age=<span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 保持连接</span></span><br><span class=\"line\">Connection: keep-alive </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 会话 </span></span><br><span class=\"line\">Cookie: Hm_lvt_3bfcc098e0da26d58c321ba579b04b2f=<span class=\"number\">1527581188</span>,<span class=\"number\">1528137133</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 域名</span></span><br><span class=\"line\">Host: www.cdtopspeed.com </span><br><span class=\"line\"></span><br><span class=\"line\">Upgrade-Insecure-Requests: <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 用户代理, 使得服务器能够识别请求是通过浏览器请求过来的，其中包含浏览器的名称/版本等信息</span></span><br><span class=\"line\">User-Agent: Mozilla/<span class=\"number\">5.0</span> (Windows NT <span class=\"number\">6.1</span>; WOW64) AppleWebKit/<span class=\"number\">537.36</span> (KHTML, like Gecko) Chrome/<span class=\"number\">65.0</span><span class=\"number\">.3325</span><span class=\"number\">.181</span> Safari/<span class=\"number\">537.36</span></span><br></pre></td></tr></table></figure></p>\n<p>其中在爬虫中最重要的就是User-Agent：在下面urllib的使用中就会详细的解释User-Agent的使用</p>\n<p><strong>2.2 网页结构分析</strong></p>\n<p>通过查看网页html代码，分析要爬取数据在html当中的位置<br>此过程需要细心，只有正确的分析出需要爬去数据的html结构，后续才能顺利拿到想要的数据</p>\n<h3 id=\"3-编写爬虫，urllib的使用\"><a href=\"#3-编写爬虫，urllib的使用\" class=\"headerlink\" title=\"3.编写爬虫，urllib的使用\"></a>3.编写爬虫，urllib的使用</h3><p>使用urllib来获取百度首页的源码<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> urllib.request</span><br><span class=\"line\"></span><br><span class=\"line\">r = urllib.request.urlopen(<span class=\"string\">'https://www.baidu.com'</span>)</span><br><span class=\"line\">print(r.read().decode(<span class=\"string\">'utf-8'</span>))</span><br></pre></td></tr></table></figure></p>\n<p>按照我们的想法来说，输出的结果应该是百度首页的源码才对，但是输出却不对(多请求几次，就会出现如下的结果)，如下结果：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">script</span>&gt;</span><span class=\"undefined\"></span></span><br><span class=\"line\"><span class=\"undefined\">\t\tlocation.replace(location.href.replace(\"https://\",\"http://\"));</span></span><br><span class=\"line\"><span class=\"undefined\">\t</span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">noscript</span>&gt;</span><span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">http-equiv</span>=<span class=\"string\">\"refresh\"</span> <span class=\"attr\">content</span>=<span class=\"string\">\"0;url=http://www.baidu.com/\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">noscript</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>以上的结果并不是我们想要的，我们可以来查看一下为什么会出现这种问题的原因。我们可以想到刚才说的，请求头中的最重要的参数User-Agent参数，该参数是用来告诉服务器，请求的url是来源于哪儿的，是来源于浏览器还是来源于其他地方的。如果是来源于非浏览器的会就不会返回源码信息给你的，直接拦截掉你的请求</p>\n<p>分析以上代码中，默认提交的请求头中的User-Agent到底传递了什么值：<br>通过查看request源代码，发现传入的User-Agent的值是：Python-urllib/3.6(当前环境的Python版本信息)</p>\n<p>接下来，就是优化以上的代码，实现目的就是告诉服务器我们这个请求是来源于浏览器的。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">header = &#123;<span class=\"string\">'User-Agent'</span>: <span class=\"string\">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko)Chrome/65.0.3325.181 Safari/537.36'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">res = urllib.request.Request(<span class=\"string\">'https://www.baidu.com'</span>, headers=header)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读取url的页面源码</span></span><br><span class=\"line\">r = urllib.request.urlopen(res)</span><br><span class=\"line\"><span class=\"comment\"># decode解码，encode编码</span></span><br><span class=\"line\">print(r.read().decode(<span class=\"string\">'utf-8'</span>))</span><br></pre></td></tr></table></figure>\n<p>按照这样去解析，就可以获取到百度的首页源代码了，展示部分代码如下：<br><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">http-equiv</span>=<span class=\"string\">\"content-type\"</span> <span class=\"attr\">content</span>=<span class=\"string\">\"text/html;charset=utf-8\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">http-equiv</span>=<span class=\"string\">\"X-UA-Compatible\"</span> <span class=\"attr\">content</span>=<span class=\"string\">\"IE=Edge\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">content</span>=<span class=\"string\">\"always\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"referrer\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">name</span>=<span class=\"string\">\"theme-color\"</span> <span class=\"attr\">content</span>=<span class=\"string\">\"#2932e1\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">link</span> <span class=\"attr\">rel</span>=<span class=\"string\">\"shortcut icon\"</span> <span class=\"attr\">href</span>=<span class=\"string\">\"/favicon.ico\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"image/x-icon\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">link</span> <span class=\"attr\">rel</span>=<span class=\"string\">\"search\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"application/opensearchdescription+xml\"</span> <span class=\"attr\">href</span>=<span class=\"string\">\"/content-search.xml\"</span> <span class=\"attr\">title</span>=<span class=\"string\">\"百度搜索\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">link</span> <span class=\"attr\">rel</span>=<span class=\"string\">\"icon\"</span> <span class=\"attr\">sizes</span>=<span class=\"string\">\"any\"</span> <span class=\"attr\">mask</span> <span class=\"attr\">href</span>=<span class=\"string\">\"//www.baidu.com/img/baidu_85beaf5496f291521eb75ba38eacbd87.svg\"</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">link</span> <span class=\"attr\">rel</span>=<span class=\"string\">\"dns-prefetch\"</span> <span class=\"attr\">href</span>=<span class=\"string\">\"//s1.bdstatic.com\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">link</span> <span class=\"attr\">rel</span>=<span class=\"string\">\"dns-prefetch\"</span> <span class=\"attr\">href</span>=<span class=\"string\">\"//t1.baidu.com\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">link</span> <span class=\"attr\">rel</span>=<span class=\"string\">\"dns-prefetch\"</span> <span class=\"attr\">href</span>=<span class=\"string\">\"//t2.baidu.com\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">link</span> <span class=\"attr\">rel</span>=<span class=\"string\">\"dns-prefetch\"</span> <span class=\"attr\">href</span>=<span class=\"string\">\"//t3.baidu.com\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">link</span> <span class=\"attr\">rel</span>=<span class=\"string\">\"dns-prefetch\"</span> <span class=\"attr\">href</span>=<span class=\"string\">\"//t10.baidu.com\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">link</span> <span class=\"attr\">rel</span>=<span class=\"string\">\"dns-prefetch\"</span> <span class=\"attr\">href</span>=<span class=\"string\">\"//t11.baidu.com\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">link</span> <span class=\"attr\">rel</span>=<span class=\"string\">\"dns-prefetch\"</span> <span class=\"attr\">href</span>=<span class=\"string\">\"//t12.baidu.com\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">link</span> <span class=\"attr\">rel</span>=<span class=\"string\">\"dns-prefetch\"</span> <span class=\"attr\">href</span>=<span class=\"string\">\"//b1.bdstatic.com\"</span>/&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>百度一下，你就知道<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></span><br><span class=\"line\">...</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>通过简单的一段代码，我们就完成了对百度的网页爬取！</p>\n<h3 id=\"4-SSL-补充\"><a href=\"#4-SSL-补充\" class=\"headerlink\" title=\"4.SSL(补充)\"></a>4.SSL(补充)</h3><p>什么是 SSL 证书？</p>\n<p>SSL 证书就是遵守 SSL 安全套接层协议的服务器数字证书。</p>\n<p>而 SSL 安全协议最初是由美国网景 Netscape Communication 公司设计开发的，全称为：安全套接层协议 (Secure Sockets Layer) ， 它指定了在应用程序协议 ( 如 HTTP 、 Telnet 、 FTP) 和 TCP/IP 之间提供数据安全性分层的机制，它是在传输通信协议 (TCP/IP) 上实现的一种安全协议，采用公开密钥技术，它为 TCP/IP 连接提供数据加密、服务器认证、消息完整性以及可选的客户机认证。由于此协议很好地解决了互联网明文传输的不安全问题，很快得到了业界的支持，并已经成为国际标准。</p>\n<p>SSL 证书由浏览器中“受信任的根证书颁发机构”在验证服务器身份后颁发，具有网站身份验证和加密传输双重功能。</p>\n<p>如果能使用 https:// 来访问某个网站，就表示此网站是部署了SSL证书。一般来讲，如果此网站部署了SSL证书，则在需要加密的页面会自动从 http:// 变为 https:// ，如果没有变，你认为此页面应该加密，您也可以尝试直接手动在浏览器地址栏的http后面加上一个英文字母“ s ”后回车，如果能正常访问并出现安全锁，则表明此网站实际上是部署了SSL证书，只是此页面没有做 https:// 链接；如果不能访问，则表明此网站没有部署 SSL证书。</p>\n<p>案例:</p>\n<p>访问加密的12306的网站</p>\n<p>如果不忽略ssl的安全认证的话，网页的源码会提示ssl认证问题，需要提供ssl认证。我们在做爬虫的时候，自动设置忽略掉ssl认证即可。代码如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> ssl</span><br><span class=\"line\"><span class=\"keyword\">import</span> urllib.request</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    url = <span class=\"string\">'https://www.12306.cn/mormhweb/'</span></span><br><span class=\"line\">    <span class=\"comment\"># 忽略未经审核的ssl认证</span></span><br><span class=\"line\">    context = ssl._create_unverified_context()</span><br><span class=\"line\">    res = urllib.request.urlopen(url, context=context)</span><br><span class=\"line\">    print(res.read().decode(<span class=\"string\">'utf-8'</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    main()</span><br></pre></td></tr></table></figure>\n","categories":[{"name":"基于urllib的基础爬虫","slug":"基于urllib的基础爬虫","count":1,"path":"api/categories/基于urllib的基础爬虫.json"}],"tags":[{"name":"爬虫","slug":"爬虫","count":1,"path":"api/tags/爬虫.json"}]}